"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_book=self.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[363],{334:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>c,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>a,toc:()=>l});var o=e(4848),t=e(8453);const s={sidebar_position:8},r="Conversational Robotics",a={id:"conversational-robotics",title:"Conversational Robotics",description:"GPT + Voice + Vision Integration",source:"@site/docs/conversational-robotics.md",sourceDirName:".",slug:"/conversational-robotics",permalink:"/physical-ai-humanoid-robotics/docs/conversational-robotics",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/conversational-robotics.md",tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"Humanoid Robotics",permalink:"/physical-ai-humanoid-robotics/docs/humanoid-robotics"},next:{title:"ROS 2 Project",permalink:"/physical-ai-humanoid-robotics/docs/assessments/ros-project"}},c={},l=[{value:"GPT + Voice + Vision Integration",id:"gpt--voice--vision-integration",level:2},{value:"Natural Language Processing",id:"natural-language-processing",level:3},{value:"Voice Integration",id:"voice-integration",level:3},{value:"Vision Integration",id:"vision-integration",level:3},{value:"Learning Outcomes",id:"learning-outcomes",level:2}];function d(n){const i={h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(i.h1,{id:"conversational-robotics",children:"Conversational Robotics"}),"\n",(0,o.jsx)(i.h2,{id:"gpt--voice--vision-integration",children:"GPT + Voice + Vision Integration"}),"\n",(0,o.jsx)(i.h3,{id:"natural-language-processing",children:"Natural Language Processing"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Language understanding for robot commands"}),"\n",(0,o.jsx)(i.li,{children:"Context-aware dialogue management"}),"\n",(0,o.jsx)(i.li,{children:"Multi-turn conversation handling"}),"\n"]}),"\n",(0,o.jsx)(i.h3,{id:"voice-integration",children:"Voice Integration"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Speech recognition for command input"}),"\n",(0,o.jsx)(i.li,{children:"Text-to-speech for robot responses"}),"\n",(0,o.jsx)(i.li,{children:"Voice activity detection"}),"\n"]}),"\n",(0,o.jsx)(i.h3,{id:"vision-integration",children:"Vision Integration"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Visual attention for human-robot interaction"}),"\n",(0,o.jsx)(i.li,{children:"Object recognition for contextual responses"}),"\n",(0,o.jsx)(i.li,{children:"Gesture recognition"}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,o.jsx)(i.p,{children:"By the end of this module, you will:"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Integrate large language models with robotic systems"}),"\n",(0,o.jsx)(i.li,{children:"Implement multimodal perception for conversation"}),"\n",(0,o.jsx)(i.li,{children:"Design dialogue systems for robot interaction"}),"\n",(0,o.jsx)(i.li,{children:"Create context-aware conversational agents"}),"\n",(0,o.jsx)(i.li,{children:"Combine vision, voice, and language for natural interaction"}),"\n"]})]})}function u(n={}){const{wrapper:i}={...(0,t.R)(),...n.components};return i?(0,o.jsx)(i,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,i,e)=>{e.d(i,{R:()=>r,x:()=>a});var o=e(6540);const t={},s=o.createContext(t);function r(n){const i=o.useContext(s);return o.useMemo(function(){return"function"==typeof n?n(i):{...i,...n}},[i,n])}function a(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:r(n.components),o.createElement(s.Provider,{value:i},n.children)}}}]);